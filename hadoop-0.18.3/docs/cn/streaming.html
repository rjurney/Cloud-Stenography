<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta content="Apache Forrest" name="Generator">
<meta name="Forrest-version" content="0.8">
<meta name="Forrest-skin-name" content="pelt">
<meta name="http-equiv" content="Content-Type">
<meta name="content" content="text/html;">
<meta name="charset" content="utf-8">
<title>Hadoop Streaming</title>
<link type="text/css" href="skin/basic.css" rel="stylesheet">
<link media="screen" type="text/css" href="skin/screen.css" rel="stylesheet">
<link media="print" type="text/css" href="skin/print.css" rel="stylesheet">
<link type="text/css" href="skin/profile.css" rel="stylesheet">
<script src="skin/getBlank.js" language="javascript" type="text/javascript"></script><script src="skin/getMenu.js" language="javascript" type="text/javascript"></script><script src="skin/fontsize.js" language="javascript" type="text/javascript"></script>
<link rel="shortcut icon" href="images/favicon.ico">
</head>
<body onload="init()">
<script type="text/javascript">ndeSetTextSize();</script>
<div id="top">
<!--+
    |breadtrail
    +-->
<div class="breadtrail">
<a href="http://www.apache.org/">Apache</a> &gt; <a href="http://hadoop.apache.org/">Hadoop</a> &gt; <a href="http://hadoop.apache.org/core/">Core</a><script src="skin/breadcrumbs.js" language="JavaScript" type="text/javascript"></script>
</div>
<!--+
    |header
    +-->
<div class="header">
<!--+
    |start group logo
    +-->
<div class="grouplogo">
<a href="http://hadoop.apache.org/"><img class="logoImage" alt="Hadoop" src="images/hadoop-logo.jpg" title="Apache Hadoop"></a>
</div>
<!--+
    |end group logo
    +-->
<!--+
    |start Project Logo
    +-->
<div class="projectlogo">
<a href="http://hadoop.apache.org/core/"><img class="logoImage" alt="Hadoop" src="images/core-logo.gif" title="Scalable Computing Platform"></a>
</div>
<!--+
    |end Project Logo
    +-->
<!--+
    |start Search
    +-->
<div class="searchbox">
<form action="http://www.google.com/search" method="get" class="roundtopsmall">
<input value="hadoop.apache.org" name="sitesearch" type="hidden"><input onFocus="getBlank (this, 'Search the site with google');" size="25" name="q" id="query" type="text" value="Search the site with google">&nbsp; 
                    <input name="Search" value="Search" type="submit">
</form>
</div>
<!--+
    |end search
    +-->
<!--+
    |start Tabs
    +-->
<ul id="tabs">
<li>
<a class="unselected" href="http://hadoop.apache.org/core/">项目</a>
</li>
<li>
<a class="unselected" href="http://wiki.apache.org/hadoop">维基</a>
</li>
<li class="current">
<a class="selected" href="index.html">Hadoop 0.18文档</a>
</li>
</ul>
<!--+
    |end Tabs
    +-->
</div>
</div>
<div id="main">
<div id="publishedStrip">
<!--+
    |start Subtabs
    +-->
<div id="level2tabs"></div>
<!--+
    |end Endtabs
    +-->
<script type="text/javascript"><!--
document.write("Last Published: " + document.lastModified);
//  --></script>
</div>
<!--+
    |breadtrail
    +-->
<div class="breadtrail">

             &nbsp;
           </div>
<!--+
    |start Menu, mainarea
    +-->
<!--+
    |start Menu
    +-->
<div id="menu">
<div onclick="SwitchMenu('menu_selected_1.1', 'skin/')" id="menu_selected_1.1Title" class="menutitle" style="background-image: url('skin/images/chapter_open.gif');">文档</div>
<div id="menu_selected_1.1" class="selectedmenuitemgroup" style="display: block;">
<div class="menuitem">
<a href="index.html">概述</a>
</div>
<div class="menuitem">
<a href="quickstart.html">快速入门</a>
</div>
<div class="menuitem">
<a href="cluster_setup.html">集群搭建</a>
</div>
<div class="menuitem">
<a href="hdfs_design.html">HDFS构架设计</a>
</div>
<div class="menuitem">
<a href="hdfs_user_guide.html">HDFS使用指南</a>
</div>
<div class="menuitem">
<a href="hdfs_permissions_guide.html">HDFS权限指南</a>
</div>
<div class="menuitem">
<a href="hdfs_quota_admin_guide.html">HDFS配额管理指南</a>
</div>
<div class="menuitem">
<a href="commands_manual.html">命令手册</a>
</div>
<div class="menuitem">
<a href="hdfs_shell.html">FS Shell使用指南</a>
</div>
<div class="menuitem">
<a href="distcp.html">DistCp使用指南</a>
</div>
<div class="menuitem">
<a href="mapred_tutorial.html">Map-Reduce教程</a>
</div>
<div class="menuitem">
<a href="native_libraries.html">Hadoop本地库</a>
</div>
<div class="menupage">
<div class="menupagetitle">Streaming</div>
</div>
<div class="menuitem">
<a href="hadoop_archives.html">Hadoop Archives</a>
</div>
<div class="menuitem">
<a href="hod.html">Hadoop On Demand</a>
</div>
<div class="menuitem">
<a href="http://hadoop.apache.org/core/docs/r0.18.2/api/index.html">API参考</a>
</div>
<div class="menuitem">
<a href="http://hadoop.apache.org/core/docs/r0.18.2/jdiff/changes.html">API Changes</a>
</div>
<div class="menuitem">
<a href="http://wiki.apache.org/hadoop/">维基</a>
</div>
<div class="menuitem">
<a href="http://wiki.apache.org/hadoop/FAQ">常见问题</a>
</div>
<div class="menuitem">
<a href="http://hadoop.apache.org/core/mailing_lists.html">邮件列表</a>
</div>
<div class="menuitem">
<a href="http://hadoop.apache.org/core/docs/r0.18.2/releasenotes.html">发行说明</a>
</div>
<div class="menuitem">
<a href="http://hadoop.apache.org/core/docs/r0.18.2/changes.html">变更日志</a>
</div>
</div>
<div id="credit"></div>
<div id="roundbottom">
<img style="display: none" class="corner" height="15" width="15" alt="" src="skin/images/rc-b-l-15-1body-2menu-3menu.png"></div>
<!--+
  |alternative credits
  +-->
<div id="credit2"></div>
</div>
<!--+
    |end Menu
    +-->
<!--+
    |start content
    +-->
<div id="content">
<div title="Portable Document Format" class="pdflink">
<a class="dida" href="streaming.pdf"><img alt="PDF -icon" src="skin/images/pdfdoc.gif" class="skin"><br>
        PDF</a>
</div>
<h1>Hadoop Streaming</h1>
<div id="minitoc-area">
<ul class="minitoc">
<li>
<a href="#Hadoop+Streaming">Hadoop Streaming</a>
</li>
<li>
<a href="#Streaming%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86">Streaming工作原理</a>
</li>
<li>
<a href="#%E5%B0%86%E6%96%87%E4%BB%B6%E6%89%93%E5%8C%85%E5%88%B0%E6%8F%90%E4%BA%A4%E7%9A%84%E4%BD%9C%E4%B8%9A%E4%B8%AD">将文件打包到提交的作业中</a>
</li>
<li>
<a href="#Streaming%E9%80%89%E9%A1%B9%E4%B8%8E%E7%94%A8%E6%B3%95">Streaming选项与用法</a>
<ul class="minitoc">
<li>
<a href="#%E5%8F%AA%E4%BD%BF%E7%94%A8Mapper%E7%9A%84%E4%BD%9C%E4%B8%9A">只使用Mapper的作业</a>
</li>
<li>
<a href="#%E4%B8%BA%E4%BD%9C%E4%B8%9A%E6%8C%87%E5%AE%9A%E5%85%B6%E4%BB%96%E6%8F%92%E4%BB%B6">为作业指定其他插件</a>
</li>
<li>
<a href="#Hadoop+Streaming%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%96%87%E4%BB%B6%E5%92%8C%E6%A1%A3%E6%A1%88">Hadoop Streaming中的大文件和档案</a>
</li>
<li>
<a href="#%E4%B8%BA%E4%BD%9C%E4%B8%9A%E6%8C%87%E5%AE%9A%E9%99%84%E5%8A%A0%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0">为作业指定附加配置参数</a>
</li>
<li>
<a href="#%E5%85%B6%E4%BB%96%E9%80%89%E9%A1%B9">其他选项</a>
</li>
</ul>
</li>
<li>
<a href="#%E5%85%B6%E4%BB%96%E4%BE%8B%E5%AD%90">其他例子</a>
<ul class="minitoc">
<li>
<a href="#%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%96%B9%E6%B3%95%E5%88%87%E5%88%86%E8%A1%8C%E6%9D%A5%E5%BD%A2%E6%88%90Key%2FValue%E5%AF%B9">使用自定义的方法切分行来形成Key/Value对</a>
</li>
<li>
<a href="#%E4%B8%80%E4%B8%AA%E5%AE%9E%E7%94%A8%E7%9A%84Partitioner%E7%B1%BB">一个实用的Partitioner类 （二次排序，-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner 选项） </a>
</li>
<li>
<a href="#Hadoop%E8%81%9A%E5%90%88%E5%8A%9F%E8%83%BD%E5%8C%85%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%88-reduce+aggregate+%E9%80%89%E9%A1%B9%EF%BC%89">Hadoop聚合功能包的使用（-reduce aggregate 选项）</a>
</li>
<li>
<a href="#%E5%AD%97%E6%AE%B5%E7%9A%84%E9%80%89%E5%8F%96%EF%BC%88%E7%B1%BB%E4%BC%BC%E4%BA%8Eunix%E4%B8%AD%E7%9A%84+%27cut%27+%E5%91%BD%E4%BB%A4%EF%BC%89">字段的选取（类似于unix中的 'cut' 命令） </a>
</li>
</ul>
</li>
<li>
<a href="#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98">常见问题</a>
<ul class="minitoc">
<li>
<a href="#%E6%88%91%E8%AF%A5%E6%80%8E%E6%A0%B7%E4%BD%BF%E7%94%A8Hadoop+Streaming%E8%BF%90%E8%A1%8C%E4%B8%80%E7%BB%84%E7%8B%AC%E7%AB%8B%EF%BC%88%E7%9B%B8%E5%85%B3%EF%BC%89%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%91%A2%EF%BC%9F">我该怎样使用Hadoop Streaming运行一组独立（相关）的任务呢？</a>
</li>
<li>
<a href="#%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6%EF%BC%8C%E5%85%B6%E4%B8%AD%E6%AF%8F%E4%B8%AA%E6%96%87%E4%BB%B6%E4%B8%80%E4%B8%AAmap%EF%BC%9F">如何处理多个文件，其中每个文件一个map？</a>
</li>
<li>
<a href="#%E5%BA%94%E8%AF%A5%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%B0%91%E4%B8%AAreducer%EF%BC%9F">应该使用多少个reducer？</a>
</li>
<li>
<a href="#%E5%A6%82%E6%9E%9C%E5%9C%A8Shell%E8%84%9A%E6%9C%AC%E9%87%8C%E8%AE%BE%E7%BD%AE%E4%B8%80%E4%B8%AA%E5%88%AB%E5%90%8D%EF%BC%8C%E5%B9%B6%E6%94%BE%E5%9C%A8-mapper%E4%B9%8B%E5%90%8E%EF%BC%8CStreaming%E4%BC%9A%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C%E5%90%97%EF%BC%9F%0A%E4%BE%8B%E5%A6%82%EF%BC%8Calias+cl%3D%27cut+-fl%27%EF%BC%8C-mapper+%22cl%22%E4%BC%9A%E8%BF%90%E8%A1%8C%E6%AD%A3%E5%B8%B8%E5%90%97%EF%BC%9F">
如果在Shell脚本里设置一个别名，并放在-mapper之后，Streaming会正常运行吗？
例如，alias cl='cut -fl'，-mapper "cl"会运行正常吗？
</a>
</li>
<li>
<a href="#%E6%88%91%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8UNIX+pipes%E5%90%97%EF%BC%9F%E4%BE%8B%E5%A6%82+%E2%80%93mapper+%22cut+%E2%80%93fl+%7C+set+s%2Ffoo%2Fbar%2Fg%22%E7%AE%A1%E7%94%A8%E4%B9%88%EF%BC%9F">
我可以使用UNIX pipes吗？例如 &ndash;mapper "cut &ndash;fl | set s/foo/bar/g"管用么？
</a>
</li>
<li>
<a href="#%E5%9C%A8streaming%E4%BD%9C%E4%B8%9A%E4%B8%AD%E7%94%A8-file%E9%80%89%E9%A1%B9%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AA">在streaming作业中用-file选项运行一个分布式的超大可执行文件（例如，3.6G）时，
我得到了一个错误信息&ldquo;No space left on device&rdquo;。如何解决？
</a>
</li>
<li>
<a href="#%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E5%A4%9A%E4%B8%AA%E8%BE%93%E5%85%A5%E7%9B%AE%E5%BD%95%EF%BC%9F">如何设置多个输入目录？</a>
</li>
<li>
<a href="#%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90gzip%E6%A0%BC%E5%BC%8F%E7%9A%84%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6%EF%BC%9F">如何生成gzip格式的输出文件？</a>
</li>
<li>
<a href="#Streaming%E4%B8%AD%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89input%2Foutput+format%EF%BC%9F">Streaming中如何自定义input/output format？</a>
</li>
<li>
<a href="#Streaming%E5%A6%82%E4%BD%95%E8%A7%A3%E6%9E%90XML%E6%96%87%E6%A1%A3%EF%BC%9F">Streaming如何解析XML文档？</a>
</li>
<li>
<a href="#%E5%9C%A8streaming%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0%E8%AE%A1%E6%95%B0%E5%99%A8%EF%BC%9F">在streaming应用程序中如何更新计数器？</a>
</li>
<li>
<a href="#%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0streaming%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%8A%B6%E6%80%81%EF%BC%9F">如何更新streaming应用程序的状态？</a>
</li>
</ul>
</li>
</ul>
</div>

<a name="N10019"></a><a name="Hadoop+Streaming"></a>
<h2 class="h3">Hadoop Streaming</h2>
<div class="section">
<p>
Hadoop streaming是Hadoop的一个工具，
    它帮助用户创建和运行一类特殊的map/reduce作业，
    这些特殊的map/reduce作业是由一些可执行文件或脚本文件充当mapper或者reducer。例如： 
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper /bin/cat \
    -reducer /bin/wc
</pre>
</div>


<a name="N10027"></a><a name="Streaming%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"></a>
<h2 class="h3">Streaming工作原理</h2>
<div class="section">
<p>
在上面的例子里，mapper和reducer都是可执行文件，它们从标准输入读入数据（一行一行读），
并把计算结果发给标准输出。Streaming工具会创建一个Map/Reduce作业，
并把它发送给合适的集群，同时监视这个作业的整个执行过程。
</p>
<p>
如果一个可执行文件被用于mapper，则在mapper初始化时，
每一个mapper任务会把这个可执行文件作为一个单独的进程启动。
mapper任务运行时，它把输入切分成行并把每一行提供给可执行文件进程的标准输入。
同时，mapper收集可执行文件进程标准输出的内容，并把收到的每一行内容转化成key/value对，作为mapper的输出。
默认情况下，一行中第一个tab之前的部分作为<strong>key</strong>，之后的（不包括tab）作为<strong>value</strong>。
如果没有tab，整行作为key值，value值为null。不过，这可以定制，在下文中将会讨论如何自定义key和value的切分方式。
</p>
<p>如果一个可执行文件被用于reducer，每个reducer任务会把这个可执行文件作为一个单独的进程启动。
Reducer任务运行时，它把输入切分成行并把每一行提供给可执行文件进程的标准输入。
同时，reducer收集可执行文件进程标准输出的内容，并把每一行内容转化成key/value对，作为reducer的输出。
默认情况下，一行中第一个tab之前的部分作为key，之后的（不包括tab）作为value。在下文中将会讨论如何自定义key和value的切分方式。
</p>
<p>
这是Map/Reduce框架和streaming mapper/reducer之间的基本通信协议。
</p>
<p>
用户也可以使用java类作为mapper或者reducer。上面的例子与这里的代码等价：
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper org.apache.hadoop.mapred.lib.IdentityMapper \
    -reducer /bin/wc
</pre>
<p>用户可以设定<span class="codefrag">stream.non.zero.exit.is.failure</span> 
<span class="codefrag">true</span> 或<span class="codefrag">false</span> 来表明streaming task的返回值非零时是
<span class="codefrag">Failure</span> 
还是<span class="codefrag">Success</span>。默认情况，streaming task返回非零时表示失败。
</p>
</div>


<a name="N10056"></a><a name="%E5%B0%86%E6%96%87%E4%BB%B6%E6%89%93%E5%8C%85%E5%88%B0%E6%8F%90%E4%BA%A4%E7%9A%84%E4%BD%9C%E4%B8%9A%E4%B8%AD"></a>
<h2 class="h3">将文件打包到提交的作业中</h2>
<div class="section">
<p>
任何可执行文件都可以被指定为mapper/reducer。这些可执行文件不需要事先存放在集群上；
如果在集群上还没有，则需要用-file选项让framework把可执行文件作为作业的一部分，一起打包提交。例如：
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper myPythonScript.py \
    -reducer /bin/wc \
    -file myPythonScript.py 
</pre>
<p> 
上面的例子描述了一个用户把可执行python文件作为mapper。
其中的选项&ldquo;-file myPythonScirpt.py&rdquo;使可执行python文件作为作业提交的一部分被上传到集群的机器上。
</p>
<p>
除了可执行文件外，其他mapper或reducer需要用到的辅助文件（比如字典，配置文件等）也可以用这种方式打包上传。例如：
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper myPythonScript.py \
    -reducer /bin/wc \
    -file myPythonScript.py \
    -file myDictionary.txt
</pre>
</div>


<a name="N1006E"></a><a name="Streaming%E9%80%89%E9%A1%B9%E4%B8%8E%E7%94%A8%E6%B3%95"></a>
<h2 class="h3">Streaming选项与用法</h2>
<div class="section">
<a name="N10074"></a><a name="%E5%8F%AA%E4%BD%BF%E7%94%A8Mapper%E7%9A%84%E4%BD%9C%E4%B8%9A"></a>
<h3 class="h4">只使用Mapper的作业</h3>
<p>
有时只需要map函数处理输入数据。这时只需把mapred.reduce.tasks设置为零，Map/reduce框架就不会创建reducer任务，mapper任务的输出就是整个作业的最终输出。
</p>
<p>
为了做到向下兼容，Hadoop Streaming也支持&ldquo;-reduce None&rdquo;选项，它与&ldquo;-jobconf mapred.reduce.tasks=0&rdquo;等价。
</p>
<a name="N10080"></a><a name="%E4%B8%BA%E4%BD%9C%E4%B8%9A%E6%8C%87%E5%AE%9A%E5%85%B6%E4%BB%96%E6%8F%92%E4%BB%B6"></a>
<h3 class="h4">为作业指定其他插件</h3>
<p>
和其他普通的Map/Reduce作业一样，用户可以为streaming作业指定其他插件：
</p>
<pre class="code">
   -inputformat JavaClassName
   -outputformat JavaClassName
   -partitioner JavaClassName
   -combiner JavaClassName
</pre>
<p>用于处理输入格式的类要能返回Text类型的key/value对。如果不指定输入格式，则默认会使用TextInputFormat。
因为TextInputFormat得到的key值是LongWritable类型的（其实key值并不是输入文件中的内容，而是value偏移量），
所以key会被丢弃，只把value用管道方式发给mapper。
</p>
<p>
用户提供的定义输出格式的类需要能够处理Text类型的key/value对。如果不指定输出格式，则默认会使用TextOutputFormat类。
</p>
<a name="N10093"></a><a name="Hadoop+Streaming%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%96%87%E4%BB%B6%E5%92%8C%E6%A1%A3%E6%A1%88"></a>
<h3 class="h4">Hadoop Streaming中的大文件和档案</h3>
<p>任务使用-cacheFile和-cacheArchive选项在集群中分发文件和档案，选项的参数是用户已上传至HDFS的文件或档案的URI。这些文件和档案在不同的作业间缓存。用户可以通过fs.default.name.config配置参数的值得到文件所在的host和fs_port。
</p>
<p>
这个是使用-cacheFile选项的例子：
</p>
<pre class="code">
-cacheFile hdfs://host:fs_port/user/testfile.txt#testlink
</pre>
<p>在上面的例子里，url中#后面的部分是建立在任务当前工作目录下的符号链接的名字。这里的任务的当前工作目录下有一个&ldquo;testlink&rdquo;符号链接，它指向testfile.txt文件在本地的拷贝。如果有多个文件，选项可以写成：
</p>
<pre class="code">
-cacheFile hdfs://host:fs_port/user/testfile1.txt#testlink1 -cacheFile hdfs://host:fs_port/user/testfile2.txt#testlink2
</pre>
<p>
-cacheArchive选项用于把jar文件拷贝到任务当前工作目录并自动把jar文件解压缩。例如： 
</p>
<pre class="code">
-cacheArchive hdfs://host:fs_port/user/testfile.jar#testlink3
</pre>
<p>
在上面的例子中，testlink3是当前工作目录下的符号链接，它指向testfile.jar解压后的目录。
</p>
<p>
下面是使用-cacheArchive选项的另一个例子。其中，input.txt文件有两行内容，分别是两个文件的名字：testlink/cache.txt和testlink/cache2.txt。&ldquo;testlink&rdquo;是指向档案目录（jar文件解压后的目录）的符号链接，这个目录下有&ldquo;cache.txt&rdquo;和&ldquo;cache2.txt&rdquo;两个文件。
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
                  -input "/user/me/samples/cachefile/input.txt"  \
                  -mapper "xargs cat"  \
                  -reducer "cat"  \
                  -output "/user/me/samples/cachefile/out" \  
                  -cacheArchive 'hdfs://hadoop-nn1.example.com/user/me/samples/cachefile/cachedir.jar#testlink' \  
                  -jobconf mapred.map.tasks=1 \
                  -jobconf mapred.reduce.tasks=1 \ 
                  -jobconf mapred.job.name="Experiment"

$ ls test_jar/
cache.txt  cache2.txt

$ jar cvf cachedir.jar -C test_jar/ .
added manifest
adding: cache.txt(in = 30) (out= 29)(deflated 3%)
adding: cache2.txt(in = 37) (out= 35)(deflated 5%)

$ hadoop dfs -put cachedir.jar samples/cachefile

$ hadoop dfs -cat /user/me/samples/cachefile/input.txt
testlink/cache.txt
testlink/cache2.txt

$ cat test_jar/cache.txt 
This is just the cache string

$ cat test_jar/cache2.txt 
This is just the second cache string

$ hadoop dfs -ls /user/me/samples/cachefile/out      
Found 1 items
/user/me/samples/cachefile/out/part-00000  &lt;r 3&gt;   69

$ hadoop dfs -cat /user/me/samples/cachefile/out/part-00000
This is just the cache string   
This is just the second cache string

</pre>
<a name="N100BC"></a><a name="%E4%B8%BA%E4%BD%9C%E4%B8%9A%E6%8C%87%E5%AE%9A%E9%99%84%E5%8A%A0%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0"></a>
<h3 class="h4">为作业指定附加配置参数</h3>
<p>
用户可以使用&ldquo;-jobconf  &lt;n&gt;=&lt;v&gt;&rdquo;增加一些配置变量。例如：
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper org.apache.hadoop.mapred.lib.IdentityMapper\
    -reducer /bin/wc \
    -jobconf mapred.reduce.tasks=2
</pre>
<p>
上面的例子中，-jobconf mapred.reduce.tasks=2表明用两个reducer完成作业。
</p>
<p>
关于jobconf参数的更多细节可以参考：<a href="http://hadoop.apache.org/core/docs/current/hadoop-default.html">hadoop-default.html</a>
</p>
<a name="N100D3"></a><a name="%E5%85%B6%E4%BB%96%E9%80%89%E9%A1%B9"></a>
<h3 class="h4">其他选项</h3>
<p>
Streaming 作业的其他选项如下表：
</p>
<table class="ForrestTable" cellspacing="1" cellpadding="4">

<tr>
<th colspan="1" rowspan="1">选项</th><th colspan="1" rowspan="1">可选/必须</th><th colspan="1" rowspan="1">描述</th>
</tr>

<tr>
<td colspan="1" rowspan="1"> -cluster name </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 在本地Hadoop集群与一个或多个远程集群间切换</td>
</tr>


<tr>
<td colspan="1" rowspan="1"> -dfs  host:port or local </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 覆盖作业的HDFS配置</td>
</tr>

<tr>
<td colspan="1" rowspan="1"> -jt host:port or local </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 覆盖作业的JobTracker配置</td>
</tr>

<tr>
<td colspan="1" rowspan="1"> -additionalconfspec specfile </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 用一个类似于hadoop-site.xml的XML文件保存所有配置，从而不需要用多个"-jobconf name=value"类型的选项单独为每个配置变量赋值</td>
</tr>

<tr>
<td colspan="1" rowspan="1"> -cmdenv   name=value </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 传递环境变量给streaming命令</td>
</tr>

<tr>
<td colspan="1" rowspan="1"> -cacheFile fileNameURI </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 指定一个上传到HDFS的文件</td>
</tr>

<tr>
<td colspan="1" rowspan="1"> -cacheArchive fileNameURI </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 指定一个上传到HDFS的jar文件，这个jar文件会被自动解压缩到当前工作目录下</td>
</tr>


<tr>
<td colspan="1" rowspan="1"> -inputreader JavaClassName </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 为了向下兼容：指定一个record reader类（而不是input format类）</td>
</tr>

<tr>
<td colspan="1" rowspan="1"> -verbose </td><td colspan="1" rowspan="1"> 可选 </td><td colspan="1" rowspan="1"> 详细输出 </td>
</tr>

</table>
<p>
使用-cluster &lt;name&gt;实现&ldquo;本地&rdquo;Hadoop和一个或多个远程Hadoop集群间切换。默认情况下，使用hadoop-default.xml和hadoop-site.xml；当使用-cluster &lt;name&gt;选项时，会使用$HADOOP_HOME/conf/hadoop-&lt;name&gt;.xml。
</p>
<p>
下面的选项改变temp目录：
</p>
<pre class="code">
  -jobconf dfs.data.dir=/tmp
</pre>
<p>
下面的选项指定其他本地temp目录：
</p>
<pre class="code">
   -jobconf mapred.local.dir=/tmp/local
   -jobconf mapred.system.dir=/tmp/system
   -jobconf mapred.temp.dir=/tmp/temp
</pre>
<p>
更多有关jobconf的细节请参考：<a href="http://wiki.apache.org/hadoop/JobConfFile">http://wiki.apache.org/hadoop/JobConfFile</a>

</p>
<p>
在streaming命令中设置环境变量：
</p>
<pre class="code">
-cmdenv EXAMPLE_DIR=/home/example/dictionaries/
</pre>
</div>


<a name="N1018B"></a><a name="%E5%85%B6%E4%BB%96%E4%BE%8B%E5%AD%90"></a>
<h2 class="h3">其他例子</h2>
<div class="section">
<a name="N10191"></a><a name="%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%96%B9%E6%B3%95%E5%88%87%E5%88%86%E8%A1%8C%E6%9D%A5%E5%BD%A2%E6%88%90Key%2FValue%E5%AF%B9"></a>
<h3 class="h4">使用自定义的方法切分行来形成Key/Value对</h3>
<p>
之前已经提到，当Map/Reduce框架从mapper的标准输入读取一行时，它把这一行切分为key/value对。
在默认情况下，每行第一个tab符之前的部分作为key，之后的部分作为value（不包括tab符）。
</p>
<p>
但是，用户可以自定义，可以指定分隔符是其他字符而不是默认的tab符，或者指定在第n（n&gt;=1）个分割符处分割而不是默认的第一个。例如：
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper org.apache.hadoop.mapred.lib.IdentityMapper \
    -reducer org.apache.hadoop.mapred.lib.IdentityReducer \
    -jobconf stream.map.output.field.separator=. \
    -jobconf stream.num.map.output.key.fields=4 
</pre>
<p>
在上面的例子，&ldquo;-jobconf stream.map.output.field.separator=.&rdquo;指定&ldquo;.&rdquo;作为map输出内容的分隔符，并且从在第四个&ldquo;.&rdquo;之前的部分作为key，之后的部分作为value（不包括这第四个&ldquo;.&rdquo;）。 
如果一行中的&ldquo;.&rdquo;少于四个，则整行的内容作为key，value设为空的Text对象（就像这样创建了一个Text：new Text("")）。
</p>
<p>
同样，用户可以使用&ldquo;-jobconf stream.reduce.output.field.separator=SEP&rdquo;和&ldquo;-jobconf stream.num.reduce.output.fields=NUM&rdquo;来指定reduce输出的行中，第几个分隔符处分割key和value。
</p>
<a name="N101A7"></a><a name="%E4%B8%80%E4%B8%AA%E5%AE%9E%E7%94%A8%E7%9A%84Partitioner%E7%B1%BB"></a>
<h3 class="h4">一个实用的Partitioner类 （二次排序，-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner 选项） </h3>
<p>
Hadoop有一个工具类org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner，
它在应用程序中很有用。Map/reduce框架用这个类切分map的输出，
切分是基于key值的前缀，而不是整个key。例如：
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper org.apache.hadoop.mapred.lib.IdentityMapper \
    -reducer org.apache.hadoop.mapred.lib.IdentityReducer \
    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \
    -jobconf stream.map.output.field.separator=. \
    -jobconf stream.num.map.output.key.fields=4 \
    -jobconf map.output.key.field.separator=. \
    -jobconf num.key.fields.for.partition=2 \
    -jobconf mapred.reduce.tasks=12
</pre>
<p>
其中，<em>-jobconf stream.map.output.field.separator=.</em> 和<em>-jobconf stream.num.map.output.key.fields=4</em>是前文中的例子。Streaming用这两个变量来得到mapper的key/value对。
</p>
<p>
上面的Map/Reduce 作业中map输出的key一般是由&ldquo;.&rdquo;分割成的四块。但是因为使用了
<em>-jobconf num.key.fields.for.partition=2</em> 
选项，所以Map/Reduce框架使用key的前两块来切分map的输出。其中，
<em>-jobconf map.output.key.field.separator=.</em>
指定了这次切分使用的key的分隔符。这样可以保证在所有key/value对中，
key值前两个块值相同的所有key被分到一组，分配给一个reducer。 
</p>
<p>

<em>这种高效的方法等价于指定前两块作为主键，后两块作为副键。
主键用于切分块，主键和副键的组合用于排序。</em>一个简单的示例如下：
</p>
<p>
Map的输出（key）</p>
<pre class="code">
11.12.1.2
11.14.2.3
11.11.4.1
11.12.1.1
11.14.2.2

</pre>
<p>
切分给3个reducer（前两块的值用于切分）</p>
<pre class="code">
11.11.4.1
-----------
11.12.1.2
11.12.1.1
-----------
11.14.2.3
11.14.2.2
</pre>
<p>
在每个切分后的组内排序（四个块的值都用于排序）
</p>
<pre class="code">
11.11.4.1
-----------
11.12.1.1
11.12.1.2
-----------
11.14.2.2
11.14.2.3
</pre>
<a name="N101DF"></a><a name="Hadoop%E8%81%9A%E5%90%88%E5%8A%9F%E8%83%BD%E5%8C%85%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%88-reduce+aggregate+%E9%80%89%E9%A1%B9%EF%BC%89"></a>
<h3 class="h4">Hadoop聚合功能包的使用（-reduce aggregate 选项）</h3>
<p>
Hadoop有一个工具包&ldquo;Aggregate&rdquo;（
<a href="https://svn.apache.org/repos/asf/hadoop/core/trunk/src/java/org/apache/hadoop/mapred/lib/aggregate">https://svn.apache.org/repos/asf/hadoop/core/trunk/src/java/org/apache/hadoop/mapred/lib/aggregate</a>）。
&ldquo;Aggregate&rdquo;提供一个特殊的reducer类和一个特殊的combiner类，
并且有一系列的&ldquo;聚合器&rdquo;（&ldquo;aggregator&rdquo;）（例如&ldquo;sum&rdquo;，&ldquo;max&rdquo;，&ldquo;min&rdquo;等）用于聚合一组value的序列。
用户可以使用Aggregate定义一个mapper插件类，
这个类用于为mapper输入的每个key/value对产生&ldquo;可聚合项&rdquo;。
combiner/reducer利用适当的聚合器聚合这些可聚合项。 
</p>
<p>
要使用Aggregate，只需指定&ldquo;-reducer aggregate&rdquo;：</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper myAggregatorForKeyCount.py \
    -reducer aggregate \
    -file myAggregatorForKeyCount.py \
    -jobconf mapred.reduce.tasks=12
</pre>
<p>
python程序myAggregatorForKeyCount.py例子：
</p>
<pre class="code">
#!/usr/bin/python

import sys;

def generateLongCountToken(id):
    return "LongValueSum:" + id + "\t" + "1"

def main(argv):
    line = sys.stdin.readline();
    try:
        while line:
            line = line[:-1];
            fields = line.split("\t");
            print generateLongCountToken(fields[0]);
            line = sys.stdin.readline();
    except "end of file":
        return None
if __name__ == "__main__":
     main(sys.argv)
</pre>
<a name="N101FA"></a><a name="%E5%AD%97%E6%AE%B5%E7%9A%84%E9%80%89%E5%8F%96%EF%BC%88%E7%B1%BB%E4%BC%BC%E4%BA%8Eunix%E4%B8%AD%E7%9A%84+%27cut%27+%E5%91%BD%E4%BB%A4%EF%BC%89"></a>
<h3 class="h4">字段的选取（类似于unix中的 'cut' 命令） </h3>
<p>
Hadoop的工具类org.apache.hadoop.mapred.lib.FieldSelectionMapReduce帮助用户高效处理文本数据，
就像unix中的&ldquo;cut&rdquo;工具。工具类中的map函数把输入的key/value对看作字段的列表。
用户可以指定字段的分隔符（默认是tab），
可以选择字段列表中任意一段（由列表中一个或多个字段组成）作为map输出的key或者value。
同样，工具类中的reduce函数也把输入的key/value对看作字段的列表，用户可以选取任意一段作为reduce输出的key或value。例如： 
</p>
<pre class="code">
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper org.apache.hadoop.mapred.lib.FieldSelectionMapReduce\
    -reducer org.apache.hadoop.mapred.lib.FieldSelectionMapReduce\
    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \
    -jobconf map.output.key.field.separa=. \
    -jobconf num.key.fields.for.partition=2 \
    -jobconf mapred.data.field.separator=. \
    -jobconf map.output.key.value.fields.spec=6,5,1-3:0- \
    -jobconf reduce.output.key.value.fields.spec=0-2:5- \
    -jobconf mapred.reduce.tasks=12
</pre>
<p>
选项&ldquo;-jobconf map.output.key.value.fields.spec=6,5,1-3:0-&rdquo;指定了如何为map的输出选取key和value。Key选取规则和value选取规则由&ldquo;:&rdquo;分割。
在这个例子中，map输出的key由字段6，5，1，2和3组成。输出的value由所有字段组成（&ldquo;0-&rdquo;指字段0以及之后所有字段）。
</p>
<p>
选项&ldquo;-jobconf reduce.output.key.value.fields.spec=0-2:0-&rdquo;（译者注：此处应为&rdquo;0-2:5-&ldquo;）指定如何为reduce的输出选取value。
本例中，reduce的输出的key将包含字段0，1，2（对应于原始的字段6，5，1）。
reduce输出的value将包含起自字段5的所有字段（对应于所有的原始字段）。
</p>
</div>


<a name="N1020F"></a><a name="%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"></a>
<h2 class="h3">常见问题</h2>
<div class="section">
<a name="N10215"></a><a name="%E6%88%91%E8%AF%A5%E6%80%8E%E6%A0%B7%E4%BD%BF%E7%94%A8Hadoop+Streaming%E8%BF%90%E8%A1%8C%E4%B8%80%E7%BB%84%E7%8B%AC%E7%AB%8B%EF%BC%88%E7%9B%B8%E5%85%B3%EF%BC%89%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%91%A2%EF%BC%9F"></a>
<h3 class="h4">我该怎样使用Hadoop Streaming运行一组独立（相关）的任务呢？</h3>
<p>
多数情况下，你不需要Map Reduce的全部功能，
而只需要运行同一程序的多个实例，或者使用不同数据，或者在相同数据上使用不同的参数。
你可以通过Hadoop Streaming来实现。</p>
<a name="N1021F"></a><a name="%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6%EF%BC%8C%E5%85%B6%E4%B8%AD%E6%AF%8F%E4%B8%AA%E6%96%87%E4%BB%B6%E4%B8%80%E4%B8%AAmap%EF%BC%9F"></a>
<h3 class="h4">如何处理多个文件，其中每个文件一个map？</h3>
<p>
例如这样一个问题，在集群上压缩（zipping）一些文件，你可以使用以下几种方法：</p>
<ol>

<li>使用Hadoop Streaming和用户编写的mapper脚本程序：<ul>
  
<li> 生成一个文件，文件中包含所有要压缩的文件在HDFS上的完整路径。每个map 任务获得一个路径名作为输入。</li>
  
<li> 创建一个mapper脚本程序，实现如下功能：获得文件名，把该文件拷贝到本地，压缩该文件并把它发到期望的输出目录。</li>

</ul>
</li>

<li>使用现有的Hadoop框架：<ul>
   
<li>在main函数中添加如下命令：
<pre class="code">
       FileOutputFormat.setCompressOutput(conf, true);
       FileOutputFormat.setOutputCompressorClass(conf, org.apache.hadoop.io.compress.GzipCodec.class);
       conf.setOutputFormat(NonSplitableTextInputFormat.class);
       conf.setNumReduceTasks(0);
</pre>
</li>
   
<li>编写map函数：
<pre class="code">

       public void map(WritableComparable key, Writable value, 
                               OutputCollector output, 
                               Reporter reporter) throws IOException {
            output.collect((Text)value, null);
       }
</pre>
</li>
  
<li>注意输出的文件名和原文件名不同</li>

</ul>
</li>

</ol>
<a name="N1024A"></a><a name="%E5%BA%94%E8%AF%A5%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%B0%91%E4%B8%AAreducer%EF%BC%9F"></a>
<h3 class="h4">应该使用多少个reducer？</h3>
<p>
请参考Hadoop Wiki：<a href="mapred_tutorial.html#Reducer">Reducer</a>

</p>
<a name="N10258"></a><a name="%E5%A6%82%E6%9E%9C%E5%9C%A8Shell%E8%84%9A%E6%9C%AC%E9%87%8C%E8%AE%BE%E7%BD%AE%E4%B8%80%E4%B8%AA%E5%88%AB%E5%90%8D%EF%BC%8C%E5%B9%B6%E6%94%BE%E5%9C%A8-mapper%E4%B9%8B%E5%90%8E%EF%BC%8CStreaming%E4%BC%9A%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C%E5%90%97%EF%BC%9F%0A%E4%BE%8B%E5%A6%82%EF%BC%8Calias+cl%3D%27cut+-fl%27%EF%BC%8C-mapper+%22cl%22%E4%BC%9A%E8%BF%90%E8%A1%8C%E6%AD%A3%E5%B8%B8%E5%90%97%EF%BC%9F"></a>
<h3 class="h4">
如果在Shell脚本里设置一个别名，并放在-mapper之后，Streaming会正常运行吗？
例如，alias cl='cut -fl'，-mapper "cl"会运行正常吗？
</h3>
<p>
脚本里无法使用别名，但是允许变量替换，例如：
</p>
<pre class="code">
$ hadoop dfs -cat samples/student_marks
alice   50
bruce   70
charlie 80
dan     75

$ c2='cut -f2'; $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar \
    -input /user/me/samples/student_marks 
    -mapper \"$c2\" -reducer 'cat'  
    -output /user/me/samples/student_out 
    -jobconf mapred.job.name='Experiment'

$ hadoop dfs -ls samples/student_out
Found 1 items/user/me/samples/student_out/part-00000    &lt;r 3&gt;   16

$ hadoop dfs -cat samples/student_out/part-00000
50
70
75
80
</pre>
<a name="N10266"></a><a name="%E6%88%91%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8UNIX+pipes%E5%90%97%EF%BC%9F%E4%BE%8B%E5%A6%82+%E2%80%93mapper+%22cut+%E2%80%93fl+%7C+set+s%2Ffoo%2Fbar%2Fg%22%E7%AE%A1%E7%94%A8%E4%B9%88%EF%BC%9F"></a>
<h3 class="h4">
我可以使用UNIX pipes吗？例如 &ndash;mapper "cut &ndash;fl | set s/foo/bar/g"管用么？
</h3>
<p>
现在不支持，而且会给出错误信息&ldquo;java.io.IOException: Broken pipe&rdquo;。这或许是一个bug，需要进一步研究。
</p>
<a name="N10270"></a><a name="%E5%9C%A8streaming%E4%BD%9C%E4%B8%9A%E4%B8%AD%E7%94%A8-file%E9%80%89%E9%A1%B9%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AA"></a>
<h3 class="h4">在streaming作业中用-file选项运行一个分布式的超大可执行文件（例如，3.6G）时，
我得到了一个错误信息&ldquo;No space left on device&rdquo;。如何解决？
</h3>
<p>
配置变量stream.tmpdir指定了一个目录，在这个目录下要进行打jar包的操作。stream.tmpdir的默认值是/tmp，你需要将这个值设置为一个有更大空间的目录：
</p>
<pre class="code">
-jobconf stream.tmpdir=/export/bigspace/...
</pre>
<a name="N10281"></a><a name="%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E5%A4%9A%E4%B8%AA%E8%BE%93%E5%85%A5%E7%9B%AE%E5%BD%95%EF%BC%9F"></a>
<h3 class="h4">如何设置多个输入目录？</h3>
<p>
可以使用多个-input选项设置多个输入目录：
</p>
<pre class="code">
 hadoop jar hadoop-streaming.jar -input '/user/foo/dir1' -input '/user/foo/dir2' 
</pre>
<a name="N1028E"></a><a name="%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90gzip%E6%A0%BC%E5%BC%8F%E7%9A%84%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6%EF%BC%9F"></a>
<h3 class="h4">如何生成gzip格式的输出文件？</h3>
<p>
除了纯文本格式的输出，你还可以生成gzip文件格式的输出，你只需设置streaming作业中的选项&lsquo;-jobconf mapred.output.compress=true -jobconf mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCode&rsquo;。
</p>
<a name="N10298"></a><a name="Streaming%E4%B8%AD%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89input%2Foutput+format%EF%BC%9F"></a>
<h3 class="h4">Streaming中如何自定义input/output format？</h3>
<p>
至少在Hadoop 0.14版本以前，不支持多个jar文件。所以当指定自定义的类时，你要把他们和原有的streaming jar打包在一起，并用这个自定义的jar包替换默认的hadoop streaming jar包。
</p>
<a name="N102A2"></a><a name="Streaming%E5%A6%82%E4%BD%95%E8%A7%A3%E6%9E%90XML%E6%96%87%E6%A1%A3%EF%BC%9F"></a>
<h3 class="h4">Streaming如何解析XML文档？</h3>
<p>
你可以使用StreamXmlRecordReader来解析XML文档。
</p>
<pre class="code">
hadoop jar hadoop-streaming.jar -inputreader "StreamXmlRecord,begin=BEGIN_STRING,end=END_STRING" ..... (rest of the command)
</pre>
<p>
Map任务会把BEGIN_STRING和END_STRING之间的部分看作一条记录。
</p>
<a name="N102B3"></a><a name="%E5%9C%A8streaming%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0%E8%AE%A1%E6%95%B0%E5%99%A8%EF%BC%9F"></a>
<h3 class="h4">在streaming应用程序中如何更新计数器？</h3>
<p>
streaming进程能够使用stderr发出计数器信息。
<span class="codefrag">reporter:counter:&lt;group&gt;,&lt;counter&gt;,&lt;amount&gt;</span>
应该被发送到stderr来更新计数器。
</p>
<a name="N102C0"></a><a name="%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0streaming%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%8A%B6%E6%80%81%EF%BC%9F"></a>
<h3 class="h4">如何更新streaming应用程序的状态？</h3>
<p>
streaming进程能够使用stderr发出状态信息。
<span class="codefrag">reporter:status:&lt;message&gt;</span> 要被发送到stderr来设置状态。
</p>
</div>

</div>
<!--+
    |end content
    +-->
<div class="clearboth">&nbsp;</div>
</div>
<div id="footer">
<!--+
    |start bottomstrip
    +-->
<div class="lastmodified">
<script type="text/javascript"><!--
document.write("Last Published: " + document.lastModified);
//  --></script>
</div>
<div class="copyright">
        Copyright &copy;
         2007 <a href="http://www.apache.org/licenses/">The Apache Software Foundation.</a>
</div>
<!--+
    |end bottomstrip
    +-->
</div>
</body>
</html>
